{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sentiment_Analysis_major.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SubalakshmiAriyaselvam/ML-MAJOR-MAY/blob/main/Sentiment_Analysis_major.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "085SvCJz90FT"
      },
      "source": [
        "**1.0 Required Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qn0rs3P9FpRE"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from textblob import TextBlob\n",
        "import matplotlib.pyplot as plt        #Visualisation\n",
        "import seaborn as sns                  #Visualisation\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xn5nYOXQsISy"
      },
      "source": [
        "from bs4 import BeautifulSoup as bs\n",
        "import requests"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDG1wroBsPaQ"
      },
      "source": [
        "link = 'https://www.amazon.in/OnePlus-Mirror-Black-128GB-Storage/product-reviews/B07DJHV6VZ/ref=cm_cr_dp_d_show_all_btm?ie=UTF8&reviewerType=all_reviews'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AJphU7CQscXF"
      },
      "source": [
        "page = requests.get(link)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGSEMiKYskrq"
      },
      "source": [
        "page"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZw31_-jsss1"
      },
      "source": [
        "df = pd.DataFrame()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qdPtQqxls6W-"
      },
      "source": [
        "df['Review title']=review_title\n",
        "df['Ratings']=rate\n",
        "df['Reviews']=review_content"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3qdRKMo96lG"
      },
      "source": [
        "**1.1 Reading the dataset** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PR7KyTv8_tVz"
      },
      "source": [
        "dataset = pd.read_csv(\"train.csv\")\n",
        "dataset.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BknRqh2B_wXw"
      },
      "source": [
        "dataset.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yk74CgrZ-JWL"
      },
      "source": [
        "**1.2 Information about the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qzEGnhon8gaj"
      },
      "source": [
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGT7zpus8rWM"
      },
      "source": [
        "dataset['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zn36fMQM-Sqj"
      },
      "source": [
        "**1.3 Plotting of the Racist and Non-racist tweets in the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BuzbhOFGlW8j"
      },
      "source": [
        "sns.countplot(dataset['label'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9aq0Xy9Uxcw"
      },
      "source": [
        "dataset= dataset.dropna()\n",
        "dataset.info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEBF3K7aVg94"
      },
      "source": [
        "x=dataset.drop(\"id\",axis=1)\n",
        "x.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d5yqK-wsYsK4"
      },
      "source": [
        "print(\" The shape of X is:\", x.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt2ZwOqCb4Ez"
      },
      "source": [
        "import nltk\n",
        "## re -- regular expression\n",
        "import re\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OfB466-RW2g2"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFTM0YuRk4lH"
      },
      "source": [
        "#install tweet-preprocessor to clean tweets\n",
        "!pip install tweet-preprocessor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ayFHqrI2lE-5"
      },
      "source": [
        "# remove special characters using the regular expression library\n",
        "import re\n",
        "\n",
        "#set up punctuations we want to be replaced\n",
        "REPLACE_NO_SPACE = re.compile(\"(\\.)|(\\;)|(\\:)|(\\!)|(\\')|(\\?)|(\\,)|(\\\")|(\\|)|(\\()|(\\))|(\\[)|(\\])|(\\%)|(\\$)|(\\>)|(\\<)|(\\{)|(\\})\")\n",
        "REPLACE_WITH_SPACE = re.compile(\"(<br\\s/><br\\s/?)|(-)|(/)|(:).\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lyWn32_0lLrO"
      },
      "source": [
        "import preprocessor as p\n",
        "\n",
        "# custum function to clean the dataset (combining tweet_preprocessor and reguar expression)\n",
        "def clean_tweets(df):\n",
        "  tempArr = []\n",
        "  for line in df:\n",
        "    # send to tweet_processor\n",
        "    tmpL = p.clean(line)\n",
        "    # remove puctuation\n",
        "    tmpL = REPLACE_NO_SPACE.sub(\"\", tmpL.lower()) # convert all tweets to lower cases\n",
        "    tmpL = REPLACE_WITH_SPACE.sub(\" \", tmpL)\n",
        "    tempArr.append(tmpL)\n",
        "  return tempArr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkrPiChLlZTF"
      },
      "source": [
        "# clean training data\n",
        "train_tweet = clean_tweets(x[\"tweet\"])\n",
        "train_tweet = pd.DataFrame(train_tweet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1nX8ZDeblgrg"
      },
      "source": [
        "# append cleaned tweets to the training data\n",
        "x[\"clean_tweet\"] = train_tweet\n",
        "\n",
        "# compare the cleaned and uncleaned tweets\n",
        "x.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfTwB3AmZH_E"
      },
      "source": [
        "corpus = x[\"clean_tweet\"]\n",
        "corpus.tail()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVsXyOTwZP19"
      },
      "source": [
        "corpus.head(20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbAkjiE1idlh"
      },
      "source": [
        "corpus_data = corpus.values.tolist()\n",
        "corpus_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCiXGvNnnqRd"
      },
      "source": [
        "x.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1Gu-_WWbVZY"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "tfidf_vect = TfidfVectorizer()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O13mcpV8aUYr"
      },
      "source": [
        "sample=['this is a sentence is',\n",
        "        'this is another sentence',\n",
        "        'third document is here']\n",
        "        \n",
        "data=tfidf_vect.fit(sample)\n",
        "print(data.vocabulary_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3Q_Ob_BbxYx"
      },
      "source": [
        "print(tfidf_vect.get_feature_names())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSfHKrAtb3KT"
      },
      "source": [
        "data=tfidf_vect.transform(sample)\n",
        "print(data.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50JDLVgbb6Ez"
      },
      "source": [
        "print(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Syzin086awhU"
      },
      "source": [
        "print(data.toarray())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hA5Bu2hta2KU"
      },
      "source": [
        "df = pd.DataFrame(data.toarray(),columns=tfidf_vect.get_feature_names())\n",
        "print(df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMyNYOk9dMpG"
      },
      "source": [
        "sample_data = dataset[0:10]\n",
        "sample_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJlq2Jwcj_up"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(analyzer=clean_tweets)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qo4Mnc-Ve9F2"
      },
      "source": [
        "X = vectorizer.fit_transform(sample_data['tweet'])\n",
        "print(X.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_f6ZUdwFeNUe"
      },
      "source": [
        "df = pd.DataFrame(data.toarray(),columns=tfidf2_vect.get_feature_names())\n",
        "df.head(10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1vGUt7yln2f"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# extract the labels from the train data\n",
        "y = x.label.values\n",
        "\n",
        "# use 70% for the training and 30% for the test\n",
        "x_train, x_test, y_train, y_test = train_test_split(x.clean_tweet.values, y, \n",
        "                                                    stratify=y, \n",
        "                                                    random_state=1, \n",
        "                                                    test_size=0.3, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wyqe4sBHlvF3"
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8q6d3VUvYhdC"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdRoF7PcFICU"
      },
      "source": [
        "score,acc = model.evaluate(X_test, y_test, verbose = 2, batch_size = 64)\n",
        "print(\"score: %.2f\" % (score))\n",
        "print(\"The accuracy model training is: %.2f\" % (acc*100))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FQq0lmGXJWYW"
      },
      "source": [
        "y_pred=model.predict_classes(X_test)\n",
        "y_pred\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6rudZ-R8gT6"
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zDo6H-C8ojz"
      },
      "source": [
        "confusion_matrix = confusion_matrix(y_test,y_pred)\n",
        "sns.heatmap(confusion_matrix/np.sum(confusion_matrix), annot=True, \n",
        "            fmt='.2%', cmap='Blues')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRQe51Ae_QC3"
      },
      "source": [
        "print(classification_report(y_test,y_pred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yS9VDdyG1gwR"
      },
      "source": [
        "import math\n",
        "text = input(\"Enter the string: \")\n",
        "text_one_hot=[one_hot(words,voc_size)for words in text] \n",
        "#print(text_one_hot)\n",
        "res = [ele for ele in text_one_hot if ele != []]\n",
        "  \n",
        "text_new_one_hot = list(res)\n",
        "#print (\"List after empty list removal : \" + text_new_one_hot)\n",
        "\n",
        "\n",
        "\n",
        "own_pred = model.predict([text_new_one_hot])\n",
        "result = own_pred[0]\n",
        "#print(\"Predicted Score = {}\".format(result))\n",
        "\n",
        "if(result<0.5):\n",
        "    print(\"Negative Sentiment\")\n",
        "else:\n",
        "    print(\"Positive Sentiment\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}